{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pred.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLWsMY/SFIqtayOuuaRV1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuhuiaren0524/albert_ner/blob/main/pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mji0Fzkt5PTS"
      },
      "source": [
        "import sys, getopt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from car_ner import model, tokenizer, NER\n",
        "from car_ner import maxlen, id2label, label2id, num_labels\n",
        "\n",
        "model.load_weights('/home/CARNER/best_model.weights')\n",
        "\n",
        "                \n",
        "def bert_token(data, maxlen):\n",
        "    token_ids, segment_ids = [], []\n",
        "    for i, text in enumerate(data):\n",
        "        t_ids, s_ids = tokenizer.encode(text, maxlen=maxlen) # tokenizer 需要提前定义\n",
        "        token_ids.append(t_ids)\n",
        "        segment_ids.append(s_ids)\n",
        "    token_ids = sequence_padding(token_ids)\n",
        "    segment_ids = sequence_padding(segment_ids)\n",
        "    return [token_ids, segment_ids]\n",
        "\n",
        "\n",
        "def main():\n",
        "   argv = sys.argv[1:]\n",
        "   inputfile = ''\n",
        "   textcolumn = ''\n",
        "   try:\n",
        "      opts, args = getopt.getopt(argv,\"hi:o:c:\",[\"ifile=\",\"ofile=\",\"cloumn=\"])\n",
        "   except getopt.GetoptError:\n",
        "      print ('test.py -i <inputfile> -o <outputfile> -c <textcolumn>')\n",
        "      sys.exit(2)\n",
        "   for opt, arg in opts:\n",
        "      if opt == '-h':\n",
        "         print ('test.py -i <inputfile> -o <outputfile> -c <textcolumn>')\n",
        "         sys.exit()\n",
        "      elif opt in (\"-i\", \"--ifile\"):\n",
        "         inputfile = arg\n",
        "      elif opt in (\"-c\", \"--cloumn\"):\n",
        "         textcolumn = arg\n",
        "   print ('输入的文件为：', inputfile)\n",
        "   print ('文本所在列为: ', textcolumn)\n",
        "    \n",
        "   outputfile = inputfile.replace('.', '_car.', 1)\n",
        " \n",
        "   ftype = inputfile.split('.')[-1]\n",
        "   if ftype == 'csv':\n",
        "      df = pd.read_csv(inputfile)\n",
        "   elif ftype == 'xlsx':\n",
        "      df = pd.read_excel(inputfile)\n",
        "   else:\n",
        "      raise Exception('输入文件格式不正确，合理的输入文件格式为：\"csv\",\"xlsx\"') \n",
        "   \n",
        "   df = df.head(100)\n",
        "   print(df.head())\n",
        "    \n",
        "   pred = []\n",
        "   for text in df[textcolumn].values:\n",
        "        pred.append(NER.recognize(text, location=True))\n",
        "   \n",
        "   df[textcolumn+'_car'] = pred\n",
        "   df.to_csv(outputfile, index=False, encoding='utf-8-sig')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}