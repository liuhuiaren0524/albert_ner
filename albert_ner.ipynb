{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "albert_ner.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3rA5TQyDQvFjbNlrvrPw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuhuiaren0524/albert_ner/blob/main/albert_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrSz3AxjzzAc"
      },
      "source": [
        "#作用：加载NER的预训练模型\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "from bert4keras.backend import keras, K   #bert4keras基于keras的预训练模型加载框架，支持多种预训练模型（BERT、ALBERT、RoBERTa、ALBERT、NEZHA、GPT2、T5等）\n",
        "from bert4keras.models import build_transformer_model\n",
        "from bert4keras.tokenizers import Tokenizer\n",
        "from bert4keras.optimizers import Adam\n",
        "from bert4keras.snippets import sequence_padding, DataGenerator\n",
        "from bert4keras.snippets import open, ViterbiDecoder\n",
        "from bert4keras.layers import ConditionalRandomField\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "# 版本不一致导致需要显式定义\n",
        "# from bert4keras.snippets import to_array\n",
        "\n",
        "def to_array(*args):\n",
        "    \"\"\"批量转numpy的array\n",
        "    \"\"\"\n",
        "    results = [np.array(a) for a in args]\n",
        "    if len(args) == 1:\n",
        "        return results[0]\n",
        "    else:\n",
        "        return results\n",
        "\n",
        "# 参数\n",
        "maxlen = 256\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "bert_layers = 12\n",
        "learing_rate = 1e-5  # bert_layers越小，学习率应该要越大\n",
        "crf_lr_multiplier = 1000  # 必要时扩大CRF层的学习率\n",
        "\n",
        "\n",
        "# bert配置\n",
        "config_path = '/home/BERT/chinese_L-12_H-768_A-12/bert_config.json'\n",
        "checkpoint_path = '/home/BERT/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
        "dict_path = '/home/BERT/chinese_L-12_H-768_A-12/vocab.txt'\n",
        "\n",
        "\n",
        "# 建立分词器\n",
        "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
        "# 类别映射\n",
        "labels = ['CAR'] #标签列\n",
        "id2label = dict(enumerate(labels))\n",
        "label2id = {j: i for i, j in id2label.items()}\n",
        "num_labels = len(labels) * 2 + 1\n",
        "\n",
        "\n",
        "\n",
        "#后面的代码使用的是bert类型的模型，如果你用的是albert，那么前几行请改为：\n",
        "model = build_transformer_model(\n",
        "    config_path,\n",
        "    checkpoint_path,\n",
        "    model='albert',\n",
        ")\n",
        "output_layer = 'Transformer-FeedForward-Norm'\n",
        "output = model.get_layer(output_layer).get_output_at(bert_layers - 1)\n",
        "\n",
        "\"\"\"\n",
        "model = build_transformer_model(\n",
        "    config_path,\n",
        "    checkpoint_path,\n",
        ")\n",
        "\n",
        "output_layer = 'Transformer-%s-FeedForward-Norm' % (bert_layers - 1)\n",
        "output = model.get_layer(output_layer).output\n",
        "\"\"\"\n",
        "output = Dense(num_labels)(output)\n",
        "CRF = ConditionalRandomField(lr_multiplier=crf_lr_multiplier)\n",
        "output = CRF(output)\n",
        "\n",
        "model = Model(model.input, output)\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "class NamedEntityRecognizer(ViterbiDecoder):\n",
        "    \"\"\"命名实体识别器\n",
        "    \"\"\"\n",
        "\n",
        "    def recognize(self, text, location=False):\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        while len(tokens) > 512:\n",
        "            tokens.pop(-2)\n",
        "        mapping = tokenizer.rematch(text, tokens)\n",
        "        token_ids = tokenizer.tokens_to_ids(tokens)\n",
        "        segment_ids = [0] * len(token_ids)\n",
        "        token_ids, segment_ids = to_array([token_ids], [segment_ids])\n",
        "        nodes = model.predict([token_ids, segment_ids])[0]\n",
        "        labels = self.decode(nodes)\n",
        "        entities, starting = [], False\n",
        "        for i, label in enumerate(labels):\n",
        "            if label > 0:\n",
        "                if label % 2 == 1:\n",
        "                    starting = True\n",
        "                    entities.append([[i], id2label[(label - 1) // 2]])\n",
        "                elif starting:\n",
        "                    entities[-1][0].append(i)\n",
        "                else:\n",
        "                    starting = False\n",
        "            else:\n",
        "                starting = False\n",
        "        if location:\n",
        "            r = []\n",
        "            for w, l in entities:\n",
        "                i, j = mapping[w[0]][0], mapping[w[-1]][-1] + 1\n",
        "                r.append(('{}({}:{})'.format(text[i:j], i, j), l))\n",
        "            return r\n",
        "        else:\n",
        "            return [(text[mapping[w[0]][0]:mapping[w[-1]][-1] + 1], l) for w, l in entities]\n",
        "\n",
        "\n",
        "NER = NamedEntityRecognizer(trans=K.eval(CRF.trans), starts=[0], ends=[0])\n",
        "\n",
        "\n",
        "def evaluate(data, location=False):\n",
        "    \"\"\"评测函数\n",
        "    \"\"\"\n",
        "    X, Y, Z = 1e-10, 1e-10, 1e-10\n",
        "    for d in tqdm(data):\n",
        "        text = ''.join([i[0] for i in d])\n",
        "        R = set(NER.recognize(text, location=location))\n",
        "        if location:\n",
        "            T = set()\n",
        "            cunsum = 0\n",
        "            for w, l in d:\n",
        "                if l == 'O':\n",
        "                    cunsum += len(w)\n",
        "                else:\n",
        "                    T.add(('{}({}:{})'.format(w, cunsum, cunsum + len(w)), l))\n",
        "                    cunsum += len(w)\n",
        "        else:\n",
        "            T = set([tuple(i) for i in d if i[1] != 'O'])\n",
        "        X += len(R & T)\n",
        "        Y += len(R)\n",
        "        Z += len(T)\n",
        "    print('Text: ', text)\n",
        "    print('Pred: ', R)\n",
        "    print('True: ', T)\n",
        "    f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z\n",
        "    return f1, precision, recall\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
